{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoniaK007/Redi/blob/main/perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Perceptron\n",
        "\n",
        "Simple replica of a perceptron\n",
        "(https://de.wikipedia.org/wiki/K%C3%BCnstliches_Neuron)\n",
        "\n",
        "with transfer- and output-funktion"
      ],
      "metadata": {
        "id": "vFCADEYYoD3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import random\n",
        "import math\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_count: int) -> None:\n",
        "        self.weights = [random.uniform(-1, 1) for _ in range(input_count)]\n",
        "        self.activation = self.relu \n",
        "    \n",
        "    # sum all inputs and apply bias\n",
        "    def transfer(self, x: List[float]) -> float:\n",
        "        return sum(x[i] * self.weights[i] for i in range(len(x)))\n",
        "    \n",
        "    # apply activation function\n",
        "    def output(self, net_output: float) -> float:\n",
        "        return self.activation(net_output)\n",
        "\n",
        "    # bias + weights\n",
        "    def setWeights(self, new_weights):\n",
        "        self.weights = new_weights\n",
        "\n",
        "    def getWeights(self):\n",
        "        return self.weights\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return \"weights: \" + str(self.weights)\n",
        "        \n",
        "    #    \n",
        "    # The following are activation functions:\n",
        "    #\n",
        "    def hard_limit(self, in_value: float) -> float:\n",
        "        return 1.0 if in_value >= 0 else 0.0\n",
        "\n",
        "    def piecewise_linear(self,in_value: float) -> float:\n",
        "        if in_value >= 0.5:\n",
        "            return 1\n",
        "        elif in_value <= -0.5:\n",
        "            return 0\n",
        "        else:\n",
        "            return in_value + 0.5\n",
        "\n",
        "    def linear(self, in_value: float) -> float:\n",
        "        return in_value\n",
        "\n",
        "    def relu(self, in_value: float) -> float:\n",
        "        return max(0, float(in_value))\n",
        "\n",
        "    def sigmoid(self, in_value: float) -> float:\n",
        "        return 1 / (1 + math.exp(-1 * in_value * 10))\n",
        "\n",
        "    \n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "tT6QCiAOXY-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## logic gate implementation using a perceptron\n",
        "\n",
        "Some logic gates with preset weights"
      ],
      "metadata": {
        "id": "qhdcKwfsuV31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqPVBMYbWrAP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# NOT - GATE\n",
        "negation = Perceptron(1)\n",
        "negation.setWeights([1, -1])\n",
        "\n",
        "print(\"NOT(0) = {}\".format(negation.output(negation.transfer([1, 0]))))\n",
        "print(\"NOT(1) = {}\".format(negation.output(negation.transfer([1, 1]))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# AND - GATE\n",
        "conjunction = Perceptron(2)\n",
        "conjunction.setWeights([-1.5, 1.0, 1.0])\n",
        "\n",
        "print(\"AND(0, 0) = {}\".format(conjunction.output(conjunction.transfer([1, 0, 0]))))\n",
        "print(\"AND(0, 1) = {}\".format(conjunction.output(conjunction.transfer([1, 0, 1]))))\n",
        "print(\"AND(1, 0) = {}\".format(conjunction.output(conjunction.transfer([1, 1, 0]))))\n",
        "print(\"AND(1, 1) = {}\".format(conjunction.output(conjunction.transfer([1, 1, 1]))))"
      ],
      "metadata": {
        "id": "VDDjZrHEXGtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "a = np.zeros((10,10), np.float32)\n",
        "for x in range(0,10):\n",
        "  for y in range(0,10):\n",
        "    a[x][y] = conjunction.output(conjunction.transfer([x/10, y/10]))\n",
        "\n",
        "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "_tATqge2g4LP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OR - GATE\n",
        "\n",
        "disjunction = Perceptron(2)\n",
        "disjunction.setWeights([-0.5, 1.0, 1.0])\n",
        "\n",
        "print(\"OR(0, 0) = {}\".format(disjunction.output(disjunction.transfer([1, 0, 0]))))\n",
        "print(\"OR(0, 1) = {}\".format(disjunction.output(disjunction.transfer([1, 0, 1]))))\n",
        "print(\"OR(1, 0) = {}\".format(disjunction.output(disjunction.transfer([1, 1, 0]))))\n",
        "print(\"OR(1, 1) = {}\".format(disjunction.output(disjunction.transfer([1, 1, 1]))))\n",
        "\n"
      ],
      "metadata": {
        "id": "1xBJuQ6eYQX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "a = np.zeros((10,10), np.float32)\n",
        "for x in range(0,10):\n",
        "  for y in range(0,10):\n",
        "    a[x][y] = disjunction.output(disjunction.transfer([x/10, y/10]))\n",
        "\n",
        "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Glc-8YuZi9Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the perceptron weights\n",
        "\n",
        "Now we let the Perceptron find the weights itself by using a learning algorithm."
      ],
      "metadata": {
        "id": "_Kfszxu136DC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class PerceptronTrainer:\n",
        "\n",
        "    class GateInputOutput:\n",
        "        def __init__(self, inputs, expectedOutputs):\n",
        "            self.inputs = inputs\n",
        "            self.expectedOutputs = expectedOutputs\n",
        "\n",
        "    # hard coded truth tables for some logic gates:\n",
        "    oneInput = np.array([\n",
        "        [1, 0], \n",
        "        [1, 1]])\n",
        "    NOT_GATE = GateInputOutput(oneInput, np.array([1, 0]))\n",
        "\n",
        "    twoInputs = np.array([\n",
        "        [1, 0, 0], \n",
        "        [1, 0, 1], \n",
        "        [1, 1, 0], \n",
        "        [1, 1, 1]])\n",
        "    AND_GATE = GateInputOutput(twoInputs, np.array([0, 0, 0, 1]))\n",
        "    NAND_GATE = GateInputOutput(twoInputs, np.array([1, 1, 1, 0]))\n",
        "    OR_GATE = GateInputOutput(twoInputs, np.array([0, 1, 1, 1]))\n",
        "    XOR_GATE = GateInputOutput(twoInputs, np.array([0, 1, 1, 0]))\n",
        "\n",
        "    # #### TWIDDLE AREA: ¯\\_(ツ)_/¯ ###############################################\n",
        "    selectedInputOutput = AND_GATE\n",
        "    ITERATIONS = 30\n",
        "    LEARNING_RATE = 0.0137\n",
        "    ACTIVATION = Perceptron.relu\n",
        "    # #### :TWIDDLE AREA END ;) ###################################################\n",
        "\n",
        "    inputs = selectedInputOutput.inputs\n",
        "    expectedOutputs = selectedInputOutput.expectedOutputs\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def train(self, logicGate, input, expectedOutputs, learningRate):\n",
        "        weights = logicGate.getWeights()\n",
        "        newWeights = np.zeros(input.shape[1])\n",
        "        for idxN in range(input.shape[1]):\n",
        "            newWeights[idxN] = weights[idxN] + self.sumOfErrors(logicGate, input, expectedOutputs, learningRate, idxN)\n",
        "        #print(\"newWeights: \", newWeights)\n",
        "        logicGate.setWeights(newWeights)\n",
        "\n",
        "    def sumOfErrors(self, logicGate, input, expectedOutputs, learningRate, idxN):\n",
        "        sumOfErrors = 0\n",
        "        for row in range(input.shape[0]):\n",
        "            outputs = logicGate.output(logicGate.transfer(input[row]))\n",
        "            #print(\"outputs\", outputs)\n",
        "            sumOfErrors += learningRate * (expectedOutputs[row] - outputs) * input[row][idxN]\n",
        "        return sumOfErrors\n",
        "\n",
        "    def calcOutput(self, logicGate, inputs, expectedOutput):\n",
        "        output = np.zeros(inputs.shape[0])\n",
        "        errSum = 0\n",
        "        for r in range(inputs.shape[0]):\n",
        "            input = inputs[r]\n",
        "            output[r] = logicGate.output(logicGate.transfer(input))\n",
        "            errSum += abs(expectedOutput[r] - output[r])\n",
        "        print(\"avg. error:\", (errSum/ len(inputs)));\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "IulITVJjYi7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = PerceptronTrainer()\n",
        "logicGate = Perceptron(len(trainer.inputs[0]))\n",
        "logicGate.activation = trainer.ACTIVATION;\n",
        "\n",
        "print(\"initial Perceptron configuration: \" + str(logicGate))\n",
        "for i in range(0,trainer.ITERATIONS):\n",
        "    trainer.train(logicGate, trainer.inputs, trainer.expectedOutputs, trainer.LEARNING_RATE)\n",
        "\n",
        "print(\"Perceptron configuration: \", logicGate)\n",
        "trainer.calcOutput(logicGate, trainer.inputs, trainer.expectedOutputs)"
      ],
      "metadata": {
        "id": "2_AG3QtWbLev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import matplotlib.pyplot as plt\n",
        "a = np.zeros((11,11), np.float32)\n",
        "for x in range(0,11):\n",
        "  for y in range(0,11):\n",
        "    a[x][y] = logicGate.output(logicGate.transfer([x/10, y/10]))\n",
        "\n",
        "plt.imshow(a, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PGH8gMJicYif",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RG14ygEkjc2L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}